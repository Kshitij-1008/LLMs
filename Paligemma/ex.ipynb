{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e53a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 224, 224])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "pixel_values = torch.randn(4, 3, 224, 224)\n",
    "pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "815ab1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(in_channels = 3, out_channels = 768, kernel_size=16, stride=16, padding='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b230532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768, 14, 14])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(pixel_values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5e0d40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 196, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(pixel_values).flatten(2).transpose(-2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f146fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3267cd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = torch.tril(torch.ones(size=(8,8)))\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c021fcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3784, -0.1677,  0.6594, -2.2096,  0.9106,  0.3928,  0.5163, -1.4784],\n",
       "        [ 1.1493, -0.2649,  0.3257,  0.9281,  1.8215, -0.6997, -0.5771, -0.1153],\n",
       "        [-1.0783,  0.0145, -0.6181, -0.0283,  0.6501, -0.1685, -0.3230,  0.3624],\n",
       "        [-0.6954, -0.8433, -1.0251,  0.9460,  1.1891,  1.6096,  0.1554, -0.6210],\n",
       "        [-0.1633,  1.4113, -0.5695, -1.4110, -0.4287,  1.8338,  0.0833,  0.4711],\n",
       "        [-0.0108,  0.6817, -0.5105,  0.1147,  0.7083, -0.2359, -0.7061, -0.4890],\n",
       "        [-2.1594, -0.2978, -0.9799,  1.0172, -0.1355, -0.8475,  0.3940, -0.0637],\n",
       "        [-0.6191,  0.2975,  0.0156, -1.5250,  1.5943,  0.2346,  0.9808, -0.9203]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(size=(8,8))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3252fbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3784,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 1.1493, -0.2649,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-1.0783,  0.0145, -0.6181,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.6954, -0.8433, -1.0251,  0.9460,    -inf,    -inf,    -inf,    -inf],\n",
       "        [-0.1633,  1.4113, -0.5695, -1.4110, -0.4287,    -inf,    -inf,    -inf],\n",
       "        [-0.0108,  0.6817, -0.5105,  0.1147,  0.7083, -0.2359,    -inf,    -inf],\n",
       "        [-2.1594, -0.2978, -0.9799,  1.0172, -0.1355, -0.8475,  0.3940,    -inf],\n",
       "        [-0.6191,  0.2975,  0.0156, -1.5250,  1.5943,  0.2346,  0.9808, -0.9203]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x.masked_fill(bias== 0, float('-inf'))\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79722c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8044, 0.1956, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1796, 0.5358, 0.2846, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1291, 0.1114, 0.0929, 0.6666, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1325, 0.6397, 0.0882, 0.0380, 0.1016, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1317, 0.2633, 0.0799, 0.1494, 0.2704, 0.1052, 0.0000, 0.0000],\n",
       "        [0.0170, 0.1095, 0.0553, 0.4077, 0.1287, 0.0632, 0.2186, 0.0000],\n",
       "        [0.0435, 0.1088, 0.0821, 0.0176, 0.3981, 0.1022, 0.2155, 0.0322]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4271744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<loc0000>', '<loc0001>', '<loc0002>', '<loc0003>', '<loc0004>', '<loc0005>', '<loc0006>', '<loc0007>', '<loc0008>', '<loc0009>', '<loc0010>', '<loc0011>']\n",
      "['<seg00>', '<seg01>', '<seg02>', '<seg03>', '<seg04>', '<seg05>', '<seg06>', '<seg07>', '<seg08>', '<seg09>', '<seg10>', '<seg11>']\n"
     ]
    }
   ],
   "source": [
    "tokens = [f\"<loc{i:04d}>\" for i in range(12)]\n",
    "print(tokens)\n",
    "tokens = [f\"<seg{i:02d}>\" for i in range(12)]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787705aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 17,  1, 14,  1, 10, 20, 24,  0, 13])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.manual_seed(42)\n",
    "tokens = torch.randint(low=0, high=25, size=(10,))\n",
    "tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca19df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False,  True,  True,  True,  True,  True,  True,  True, False])\n",
      "tensor([ True,  True, False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "text_mask = (tokens != 17) & (tokens != 13)\n",
    "text_mask\n",
    "image_mask = (tokens == 17)\n",
    "image_mask\n",
    "pad_mask = (tokens == 13)\n",
    "print(f\"{text_mask}\\n{image_mask}\\n{pad_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac3498b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Shape: [Seq_Len, Embed_Dim] -> [10, 8]\n",
    "text_mask_expanded = text_mask.unsqueeze(dim=-1).expand(-1, 8)\n",
    "image_mask_expanded = image_mask.unsqueeze(dim=-1).expand(-1, 8)\n",
    "pad_mask_expanded = pad_mask.unsqueeze(dim=-1).expand(-1, 8)\n",
    "print(text_mask_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1415e+00,  1.8565e-02, -1.8058e+00,  9.2543e-01, -3.7534e-01,\n",
      "          1.0331e+00, -6.8665e-01,  6.3681e-01],\n",
      "        [ 1.1415e+00,  1.8565e-02, -1.8058e+00,  9.2543e-01, -3.7534e-01,\n",
      "          1.0331e+00, -6.8665e-01,  6.3681e-01],\n",
      "        [-7.5214e-01,  1.6487e+00, -3.9248e-01, -1.4036e+00, -7.2788e-01,\n",
      "         -5.5943e-01, -7.6884e-01,  7.6245e-01],\n",
      "        [-1.4570e+00, -1.0234e-01, -5.9915e-01,  4.7706e-01,  7.2618e-01,\n",
      "          9.1152e-02, -3.8907e-01,  5.2792e-01],\n",
      "        [-7.5214e-01,  1.6487e+00, -3.9248e-01, -1.4036e+00, -7.2788e-01,\n",
      "         -5.5943e-01, -7.6884e-01,  7.6245e-01],\n",
      "        [ 1.0868e-02, -3.3874e-01, -1.3407e+00, -5.8537e-01,  5.3619e-01,\n",
      "          5.2462e-01,  1.1412e+00,  5.1644e-02],\n",
      "        [-1.9006e+00,  2.2858e-01,  2.4859e-02, -3.4595e-01,  2.8683e-01,\n",
      "         -7.3084e-01,  1.7482e-01, -1.0939e+00],\n",
      "        [ 2.6178e-01, -7.5993e-01, -2.0461e+00, -1.5295e+00,  4.0487e-01,\n",
      "          6.3188e-01,  3.1253e-01, -3.3502e-02],\n",
      "        [ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00,  6.7842e-01,\n",
      "         -1.2345e+00, -4.3067e-02, -1.6047e+00],\n",
      "        [-1.8527e-01,  7.5276e-01,  4.0476e-01,  1.7847e-01,  2.6491e-01,\n",
      "          1.2732e+00, -1.3109e-03, -3.0360e-01]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "lookup = torch.randn(25, 8)\n",
    "input_embeds = lookup[tokens]\n",
    "print(input_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ed58ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0408,  0.9166, -1.3042, -1.1097, -1.2188,  1.1676, -1.0574, -0.1188],\n",
       "        [-0.9078,  0.3452, -0.5713, -0.2351,  1.0076, -0.7529, -0.2250, -0.4327],\n",
       "        [-1.5071, -0.4586, -0.8480,  0.5266,  0.0299, -0.0498,  1.0651,  0.8860],\n",
       "        [ 0.4640, -0.4986,  0.1289,  2.7631,  0.1405,  1.1191,  0.3152,  1.7528]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "image_features = torch.randn(4, 8)\n",
    "image_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95223f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624],\n",
       "        [-1.4570, -0.1023, -0.5992,  0.4771,  0.7262,  0.0912, -0.3891,  0.5279],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624],\n",
       "        [ 0.0109, -0.3387, -1.3407, -0.5854,  0.5362,  0.5246,  1.1412,  0.0516],\n",
       "        [-1.9006,  0.2286,  0.0249, -0.3460,  0.2868, -0.7308,  0.1748, -1.0939],\n",
       "        [ 0.2618, -0.7599, -2.0461, -1.5295,  0.4049,  0.6319,  0.3125, -0.0335],\n",
       "        [ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings = torch.zeros(10, 8)\n",
    "final_embeddings = torch.where(condition=text_mask_expanded, input=input_embeds, other=final_embeddings)\n",
    "final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e2b91ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0408,  0.9166, -1.3042, -1.1097, -1.2188,  1.1676, -1.0574, -0.1188],\n",
       "        [-0.9078,  0.3452, -0.5713, -0.2351,  1.0076, -0.7529, -0.2250, -0.4327],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624],\n",
       "        [-1.4570, -0.1023, -0.5992,  0.4771,  0.7262,  0.0912, -0.3891,  0.5279],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624],\n",
       "        [ 0.0109, -0.3387, -1.3407, -0.5854,  0.5362,  0.5246,  1.1412,  0.0516],\n",
       "        [-1.9006,  0.2286,  0.0249, -0.3460,  0.2868, -0.7308,  0.1748, -1.0939],\n",
       "        [ 0.2618, -0.7599, -2.0461, -1.5295,  0.4049,  0.6319,  0.3125, -0.0335],\n",
       "        [ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings = final_embeddings.masked_scatter(mask=image_mask_expanded, source=image_features)\n",
    "final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e622335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0408,  0.9166, -1.3042, -1.1097, -1.2188,  1.1676, -1.0574, -0.1188],\n",
       "        [-0.9078,  0.3452, -0.5713, -0.2351,  1.0076, -0.7529, -0.2250, -0.4327],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624],\n",
       "        [-1.4570, -0.1023, -0.5992,  0.4771,  0.7262,  0.0912, -0.3891,  0.5279],\n",
       "        [-0.7521,  1.6487, -0.3925, -1.4036, -0.7279, -0.5594, -0.7688,  0.7624],\n",
       "        [ 0.0109, -0.3387, -1.3407, -0.5854,  0.5362,  0.5246,  1.1412,  0.0516],\n",
       "        [-1.9006,  0.2286,  0.0249, -0.3460,  0.2868, -0.7308,  0.1748, -1.0939],\n",
       "        [ 0.2618, -0.7599, -2.0461, -1.5295,  0.4049,  0.6319,  0.3125, -0.0335],\n",
       "        [ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784, -1.2345, -0.0431, -1.6047],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(pad_mask_expanded, input=torch.zeros_like(final_embeddings), other=final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a423798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
